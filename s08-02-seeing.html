<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <link href="shared/bookhub.css" rel="stylesheet" type="text/css">
  <title>Seeing</title>
</head>
<body>

  
  <div id=navbar-top class="navbar">
    <div class="navbar-part left">
      
        <a href="s08-01-we-experience-our-world-throug.html"><img src="shared/images/batch-left.png"></a> <a href="s08-01-we-experience-our-world-throug.html">Previous Section</a>
      
    </div>
    <div class="navbar-part middle">
      <a href="index.html"><img src="shared/images/batch-up.png"></a> <a href="index.html">Table of Contents</a>
    </div>
    <div class="navbar-part right">
      
        <a href="s08-03-hearing.html">Next Section</a> <a href="s08-03-hearing.html"><img src="shared/images/batch-right.png"></a>
      
    </div>
  </div>

  <div id="book-content">
    <div class="section" id="stangor-ch04_s02" condition="start-of-chunk" version="5.0" lang="en">
    <h2 class="title editable block">
<span class="title-prefix">4.2</span> Seeing</h2>
    <div class="learning_objectives editable block" id="stangor-ch04_s02_n01">
        <h3 class="title">Learning Objectives</h3>
        <ol class="orderedlist" id="stangor-ch04_s02_l01">
            <li>Identify the key structures of the eye and the role they play in vision.</li>
            <li>Summarize how the eye and the visual cortex work together to sense and perceive the visual stimuli in the environment, including processing colors, shape, depth, and motion.</li>
        </ol>
    </div>
    <p class="para editable block" id="stangor-ch04_s02_p01">Whereas other animals rely primarily on hearing, smell, or touch to understand the world around them, human beings rely in large part on vision. A large part of our cerebral cortex is devoted to seeing, and we have substantial visual skills. Seeing begins when light falls on the eyes, initiating the process of transduction. Once this visual information reaches the visual cortex, it is processed by a variety of neurons that detect colors, shapes, and motion, and that create meaningful perceptions out of the incoming stimuli.</p>
    <p class="para editable block" id="stangor-ch04_s02_p02">The air around us is filled with a sea of <em class="emphasis">electromagnetic energy</em>; pulses of energy waves that can carry information from place to place. As you can see in <a class="xref" href="#stangor-ch04_s02_f01">Figure 4.6 "The Electromagnetic Spectrum"</a>, electromagnetic waves vary in their <span class="margin_term"><a class="glossterm">wavelength</a><span class="glossdef">The distance between one wave peak and the next wave peak.</span></span>—<em class="emphasis">the distance between one wave peak and the next wave peak</em>, with the shortest gamma waves being only a fraction of a millimeter in length and the longest radio waves being hundreds of kilometers long. Humans are blind to almost all of this energy—our eyes detect only the range from about 400 to 700 billionths of a meter, the part of the electromagnetic spectrum known as the <em class="emphasis">visible spectrum</em>.</p>
    <div class="figure large editable block" id="stangor-ch04_s02_f01">
        <p class="title"><span class="title-prefix">Figure 4.6</span> The Electromagnetic Spectrum</p>
        <img src="section_08/b4eaddac5823123ca0aa5e6abe24da3d.jpg">
        <p class="para">Only a small fraction of the electromagnetic energy that surrounds us (the visible spectrum) is detectable by the human eye.</p>
    </div>
    <div class="section" id="stangor-ch04_s02_s01">
        <h2 class="title editable block">The Sensing Eye and the Perceiving Visual Cortex</h2>
        <p class="para editable block" id="stangor-ch04_s02_s01_p01">As you can see in <a class="xref" href="#stangor-ch04_s02_s01_f01">Figure 4.7 "Anatomy of the Human Eye"</a>, light enters the eye through the <span class="margin_term"><a class="glossterm">cornea</a><span class="glossdef">A clear covering that protects the eye and begins to focus the incoming light.</span></span>, <em class="emphasis">a clear covering that protects the eye and begins to focus the incoming light.</em> The light then passes through the <span class="margin_term"><a class="glossterm">pupil</a><span class="glossdef">The small opening in the center of the eye that allows light to enter.</span></span>, <em class="emphasis">a small opening in the center of the eye</em>. The pupil is surrounded by the <span class="margin_term"><a class="glossterm">iris</a><span class="glossdef">The colored part of the eye that controls the size of the pupil by constricting or dilating in response to light intensity.</span></span>, <em class="emphasis">the colored part of the eye that controls the size of the pupil by constricting or dilating in response to light intensity</em>. When we enter a dark movie theater on a sunny day, for instance, muscles in the iris open the pupil and allow more light to enter. Complete adaptation to the dark may take up to 20 minutes.</p>
        <p class="para editable block" id="stangor-ch04_s02_s01_p02">Behind the pupil is the <span class="margin_term"><a class="glossterm">lens</a><span class="glossdef">A structure that focuses the incoming light on the retina.</span></span>, <em class="emphasis">a structure that focuses the incoming light on the</em> <span class="margin_term"><a class="glossterm">retina</a><span class="glossdef">The layer of tissue at the back of the eye that contains photoreceptor cells.</span></span>, <em class="emphasis">the layer of tissue at the back of the eye that contains photoreceptor cells</em>. As our eyes move from near objects to distant objects, a process known as <em class="emphasis">visual accommodation</em> occurs. <span class="margin_term"><a class="glossterm">Visual accommodation</a><span class="glossdef">The process of changing the curvature of the lens to keep the light entering the eye focused on the retina.</span></span> is <em class="emphasis">the process of changing the curvature of the lens to keep the light entering the eye focused on the retina.</em> Rays from the top of the image strike the bottom of the retina and vice versa, and rays from the left side of the image strike the right part of the retina and vice versa, causing the image on the retina to be upside down and backward. Furthermore, the image projected on the retina is flat, and yet our final perception of the image will be three dimensional.</p>
        <div class="figure large medium-height editable block" id="stangor-ch04_s02_s01_f01">
            <p class="title"><span class="title-prefix">Figure 4.7</span> Anatomy of the Human Eye</p>
            <img src="section_08/f8f7d23e8173735d0702cb3e9159503d.jpg">
            <p class="para">Light enters the eye through the transparent cornea, passing through the pupil at the center of the iris. The lens adjusts to focus the light on the retina, where it appears upside down and backward. Receptor cells on the retina send information via the optic nerve to the visual cortex.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p03">Accommodation is not always perfect, and in some cases the light that is hitting the retina is a bit out of focus. As you can see in <a class="xref" href="#stangor-ch04_s02_s01_f02">Figure 4.8 "Normal, Nearsighted, and Farsighted Eyes"</a>, if the focus is in front of the retina, we say that the person is <em class="emphasis">nearsighted</em>, and when the focus is behind the retina we say that the person is <em class="emphasis">farsighted</em>. Eyeglasses and contact lenses correct this problem by adding another lens in front of the eye, and laser eye surgery corrects the problem by reshaping the eye’s own lens.</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s01_f02">
            <p class="title"><span class="title-prefix">Figure 4.8</span> Normal, Nearsighted, and Farsighted Eyes</p>
            <img src="section_08/f2834b8767c2db01234fe11247e1682b.jpg">
            <p class="para">For people with normal vision (left), the lens properly focuses incoming light on the retina. For people who are nearsighted (center), images from far objects focus too far in front of the retina, whereas for people who are farsighted (right), images from near objects focus too far behind the retina. Eyeglasses solve the problem by adding a secondary, corrective, lens.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p04">The retina contains layers of neurons specialized to respond to light (see <a class="xref" href="#stangor-ch04_s02_s01_f03">Figure 4.9 "The Retina With Its Specialized Cells"</a>). As light falls on the retina, it first activates receptor cells known as <em class="emphasis">rods</em> and <em class="emphasis">cones.</em> The activation of these cells then spreads to the <em class="emphasis">bipolar cells</em> and then to the <em class="emphasis">ganglion cells</em>, which gather together and converge, like the strands of a rope, forming the <em class="emphasis">optic nerve</em>. The <span class="margin_term"><a class="glossterm">optic nerve</a><span class="glossdef">A collection of millions of ganglion neurons that sends vast amounts of visual information, via the thalamus, to the brain.</span></span> is <em class="emphasis">a collection of millions of ganglion neurons that sends vast amounts of visual information, via the thalamus, to the brain</em>. Because the retina and the optic nerve are active processors and analyzers of visual information, it is not inappropriate to think of these structures as an extension of the brain itself.</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s01_f03">
            <p class="title"><span class="title-prefix">Figure 4.9</span> The Retina With Its Specialized Cells</p>
            <img src="section_08/e618be902e39dc0da00285ca2f422454.jpg">
            <p class="para">When light falls on the retina, it creates a photochemical reaction in the rods and cones at the back of the retina. The reactions then continue to the bipolar cells, the ganglion cells, and eventually to the optic nerve.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p05"><span class="margin_term"><a class="glossterm">Rods</a><span class="glossdef">Visual neurons that specialize in detecting black, white, and gray colors.</span></span> are <em class="emphasis">visual neurons that specialize in detecting black, white, and gray colors</em>. There are about 120 million rods in each eye. The rods do not provide a lot of detail about the images we see, but because they are highly sensitive to shorter-waved (darker) and weak light, they help us see in dim light, for instance, at night. Because the rods are located primarily around the edges of the retina, they are particularly active in peripheral vision (when you need to see something at night, try looking away from what you want to see). <span class="margin_term"><a class="glossterm">Cones</a><span class="glossdef">Visual neurons that are specialized in detecting fine detail and colors.</span></span> are <em class="emphasis">visual neurons that are specialized in detecting fine detail and colors</em>. The 5 million or so cones in each eye enable us to see in color, but they operate best in bright light. The cones are located primarily in and around the <span class="margin_term"><a class="glossterm">fovea</a><span class="glossdef">The central point of the retina.</span></span>, which is <em class="emphasis">the central point of the retina</em>.</p>
        <p class="para editable block" id="stangor-ch04_s02_s01_p06">To demonstrate the difference between rods and cones in attention to detail, choose a word in this text and focus on it. Do you notice that the words a few inches to the side seem more blurred? This is because the word you are focusing on strikes the detail-oriented cones, while the words surrounding it strike the less-detail-oriented rods, which are located on the periphery.</p>
        <div class="figure large medium-height editable block" id="stangor-ch04_s02_s01_f04">
            <p class="title"><span class="title-prefix">Figure 4.10</span> Mona Lisa’s Smile</p>
            <img src="section_08/782ef5dd4e91a075ecd12c4626dc570a.jpg">
            <p class="para">Margaret Livingstone (2002)<span class="footnote" id="fwk-stangor-fn04_012">Livingstone M. S. (2000). Is it warm? Is it real? Or just low spatial frequency? <em class="emphasis">Science, 290</em>, 1299.</span> found an interesting effect that demonstrates the different processing capacities of the eye’s rods and cones—namely, that the Mona Lisa’s smile, which is widely referred to as “elusive,” is perceived differently depending on how one looks at the painting. Because Leonardo da Vinci painted the smile in low-detail brush strokes, these details are better perceived by our peripheral vision (the rods) than by the cones. Livingstone found that people rated the Mona Lisa as more cheerful when they were instructed to focus on her eyes than they did when they were asked to look directly at her mouth. As Livingstone put it, “She smiles until you look at her mouth, and then it fades, like a dim star that disappears when you look directly at it.”</p>
            <div class="copyright">
                <p class="para">Source: Photo courtesy of the Louvre Museum, <a class="link" target="_blank" href="http://commons.wikimedia.org/wiki/File:Mona_Lisa_detail_face.jpg">http://commons.wikimedia.org/wiki/File:Mona_Lisa_detail_face.jpg</a>.</p>
            </div>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p07">As you can see in <a class="xref" href="#stangor-ch04_s02_s01_f05">Figure 4.11 "Pathway of Visual Images Through the Thalamus and Into the Visual Cortex"</a>, the sensory information received by the retina is relayed through the thalamus to corresponding areas in the visual cortex, which is located in the occipital lobe at the back of the brain. Although the principle of contralateral control might lead you to expect that the left eye would send information to the right brain hemisphere and vice versa, nature is smarter than that. In fact, the left and right eyes each send information to both the left and the right hemisphere, and the visual cortex processes each of the cues separately and in parallel. This is an adaptational advantage to an organism that loses sight in one eye, because even if only one eye is functional, both hemispheres will still receive input from it.</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s01_f05">
            <p class="title"><span class="title-prefix">Figure 4.11</span> Pathway of Visual Images Through the Thalamus and Into the Visual Cortex</p>
            <img src="section_08/640912d55e32911ce242b2e29943780c.jpg">
            <p class="para">The left and right eyes each send information to both the left and the right brain hemisphere.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p08">The visual cortex is made up of specialized neurons that turn the sensations they receive from the optic nerve into meaningful images. Because there are no photoreceptor cells at the place where the optic nerve leaves the retina, a hole or <em class="emphasis">blind spot</em> in our vision is created (see <a class="xref" href="#stangor-ch04_s02_s01_f06">Figure 4.12 "Blind Spot Demonstration"</a>). When both of our eyes are open, we don’t experience a problem because our eyes are constantly moving, and one eye makes up for what the other eye misses. But the visual system is also designed to deal with this problem if only one eye is open—the visual cortex simply fills in the small hole in our vision with similar patterns from the surrounding areas, and we never notice the difference. The ability of the visual system to cope with the blind spot is another example of how sensation and perception work together to create meaningful experience.</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s01_f06">
            <p class="title"><span class="title-prefix">Figure 4.12</span> Blind Spot Demonstration</p>
            <img src="section_08/c7831c0a985ce9921723f00288fd20b0.jpg">
            <p class="para">You can get an idea of the extent of your blind spot (the place where the optic nerve leaves the retina) by trying this demonstration. Close your left eye and stare with your right eye at the cross in the diagram. You should be able to see the elephant image to the right (don’t look at it, just notice that it is there). If you can’t see the elephant, move closer or farther away until you can. Now slowly move so that you are closer to the image while you keep looking at the cross. At one distance (probably a foot or so), the elephant will completely disappear from view because its image has fallen on the blind spot.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p09">Perception is created in part through the simultaneous action of thousands of <span class="margin_term"><a class="glossterm">feature detector neurons</a><span class="glossdef">Specialized neurons, located in the visual cortex, that respond to the strength, angles, shapes, edges, and movements of a visual stimulus.</span></span>—<em class="emphasis">specialized neurons, located in the visual cortex, that respond to the strength, angles, shapes, edges, and movements of a visual stimulus</em> (Kelsey, 1997; Livingstone &amp; Hubel, 1988).<span class="footnote" id="fwk-stangor-fn04_013">Kelsey, C.A. (1997). Detection of visual information. In W. R. Hendee &amp; P. N. T. Wells (Eds.), <em class="emphasis">The perception of visual information</em> (2nd ed.). New York, NY: Springer Verlag; Livingstone, M., &amp; Hubel, D. (1998). Segregation of form, color, movement, and depth: Anatomy, physiology, and perception. <em class="emphasis">Science, 240</em>, 740–749.</span> The feature detectors work in parallel, each performing a specialized function. When faced with a red square, for instance, the parallel line feature detectors, the horizontal line feature detectors, and the red color feature detectors all become activated. This activation is then passed on to other parts of the visual cortex where other neurons compare the information supplied by the feature detectors with images stored in memory. Suddenly, in a flash of recognition, the many neurons fire together, creating the single image of the red square that we experience (Rodriguez et al., 1999).<span class="footnote" id="fwk-stangor-fn04_014">Rodriguez, E., George, N., Lachaux, J.-P., Martinerie, J., Renault, B., &amp; Varela, F. J. (1999). Perception’s shadow: Long-distance synchronization of human brain activity. <em class="emphasis">Nature, 397</em>(6718), 430–433.</span></p>
        <div class="figure large small-height editable block" id="stangor-ch04_s02_s01_f07">
            <p class="title"><span class="title-prefix">Figure 4.13</span> The Necker Cube</p>
            <img src="section_08/483f6b6c12ac7534c6d4d9dba817118b.jpg">
            <p class="para">The Necker cube is an example of how the visual system creates perceptions out of sensations. We do not see a series of lines, but rather a cube. Which cube we see varies depending on the momentary outcome of perceptual processes in the visual cortex.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s01_p10">Some feature detectors are tuned to selectively respond to particularly important objects, for instance, faces, smiles, and other parts of the body (Downing, Jiang, Shuman, &amp; Kanwisher, 2001; Haxby et al., 2001).<span class="footnote" id="fwk-stangor-fn04_015">Downing, P. E., Jiang, Y., Shuman, M., &amp; Kanwisher, N. (2001). A cortical area selective for visual processing of the human body. <em class="emphasis">Science, 293</em>(5539), 2470–2473; Haxby, J. V., Gobbini, M. I., Furey, M. L., Ishai, A., Schouten, J. L., &amp; Pietrini, P. (2001). Distributed and overlapping representations of faces and objects in ventral temporal cortex. <em class="emphasis">Science, 293</em>(5539), 2425–2430.</span> When researchers disrupted face recognition areas of the cortex using the magnetic pulses of transcranial magnetic stimulation (TMS), people were temporarily unable to recognize faces, and yet they were still able to recognize houses (McKone, Kanwisher, &amp; Duchaine, 2007; Pitcher, Walsh, Yovel, &amp; Duchaine, 2007).<span class="footnote" id="fwk-stangor-fn04_016">McKone, E., Kanwisher, N., &amp; Duchaine, B. C. (2007). Can generic expertise explain special processing for faces? <em class="emphasis">Trends in Cognitive Sciences, 11</em>, 8–15; Pitcher, D., Walsh, V., Yovel, G., &amp; Duchaine, B. (2007). TMS evidence for the involvement of the right occipital face area in early face processing. <em class="emphasis">Current Biology, 17</em>, 1568–1573.</span></p>
    </div>
    <div class="section" id="stangor-ch04_s02_s02">
        <h2 class="title editable block">Perceiving Color</h2>
        <p class="para editable block" id="stangor-ch04_s02_s02_p01">It has been estimated that the human visual system can detect and discriminate among 7 million color variations (Geldard, 1972),<span class="footnote" id="fwk-stangor-fn04_017">Geldard, F. A. (1972). <em class="emphasis">The human senses</em> (2nd ed.). New York, NY: John Wiley &amp; Sons.</span> but these variations are all created by the combinations of the three primary colors: red, green, and blue. <em class="emphasis">The shade of a color</em>, known as <span class="margin_term"><a class="glossterm">hue</a><span class="glossdef">Color conveyed by the wavelength of the light that enters the eye.</span></span>, is conveyed by the wavelength of the light that enters the eye (we see shorter wavelengths as more blue and longer wavelengths as more red), and we detect brightness from the <em class="emphasis">intensity</em> or height of the wave (bigger or more intense waves are perceived as brighter).</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s02_f01">
            <p class="title"><span class="title-prefix">Figure 4.14</span> Low- and High-Frequency Sine Waves and Low- and High-Intensity Sine Waves and Their Corresponding Colors</p>
            <img src="section_08/ace0c50114b5b55efbad729899a07099.jpg">
            <p class="para">Light waves with shorter frequencies are perceived as more blue than red; light waves with higher intensity are seen as brighter.</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s02_p02">In his important research on color vision, Hermann von Helmholtz (1821–1894) theorized that color is perceived because the cones in the retina come in three types. One type of cone reacts primarily to blue light (short wavelengths), another reacts primarily to green light (medium wavelengths), and a third reacts primarily to red light (long wavelengths). The visual cortex then detects and compares the strength of the signals from each of the three types of cones, creating the experience of color. According to this <span class="margin_term"><a class="glossterm">Young-Helmholtz trichromatic color theory</a><span class="glossdef">The theory of color perception that proposes that what color we see depends on the mix of the signals from the three types of cones.</span></span>, <em class="emphasis">what color we see depends on the mix of the signals from the three types of cones</em>. If the brain is receiving primarily red and blue signals, for instance, it will perceive purple; if it is receiving primarily red and green signals it will perceive yellow; and if it is receiving messages from all three types of cones it will perceive white.</p>
        <p class="para editable block" id="stangor-ch04_s02_s02_p03">The different functions of the three types of cones are apparent in people who experience <span class="margin_term"><a class="glossterm">color blindness</a><span class="glossdef">The inability to detect either green and/or red colors.</span></span>—<em class="emphasis">the inability to detect either green and/or red colors.</em> About 1 in 50 people, mostly men, lack functioning in the red- or green-sensitive cones, leaving them only able to experience either one or two colors (<a class="xref" href="#stangor-ch04_s02_s02_f02">Figure 4.15</a>).</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s02_f02">
            <p class="title"><span class="title-prefix">Figure 4.15</span> </p>
            <img src="section_08/edac27a4100f44ddac6dd84485fadb79.jpg">
            <p class="para">People with normal color vision can see the number 42 in the first image and the number 12 in the second (they are vague but apparent). However, people who are color blind cannot see the numbers at all.</p>
            <div class="copyright">
                <p class="para">Source: Courtesy of <a class="link" target="_blank" href="http://commons.wikimedia.org/wiki/File:Ishihara_11.PNG">http://commons.wikimedia.org/wiki/File:Ishihara_11.PNG</a> and <a class="link" target="_blank" href="http://commons.wikimedia.org/wiki/File:Ishihara_23.PNG">http://commons.wikimedia.org/wiki/File:Ishihara_23.PNG</a>.</p>
            </div>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s02_p04">The trichromatic color theory cannot explain all of human vision, however. For one, although the color purple does appear to us as a mixing of red and blue, yellow does not appear to be a mix of red and green. And people with color blindness, who cannot see either green or red, nevertheless can still see yellow. An alternative approach to the Young-Helmholtz theory, known as the <span class="margin_term"><a class="glossterm">opponent-process color theory</a><span class="glossdef">The theory of color perception that proposes that we analyze sensory information in three sets of “opponent colors”: red-green, yellow-blue, and white-black.</span></span>, <em class="emphasis">proposes that we analyze sensory information not in terms of three colors but rather in three sets of “opponent colors”: red-green, yellow-blue, and white-black.</em> Evidence for the opponent-process theory comes from the fact that some neurons in the retina and in the visual cortex are excited by one color (e.g., red) but inhibited by another color (e.g., green).</p>
        <p class="para editable block" id="stangor-ch04_s02_s02_p05">One example of opponent processing occurs in the experience of an afterimage. If you stare at the flag on the left side of <a class="xref" href="#stangor-ch04_s02_s02_f03">Figure 4.16 "U.S. Flag"</a> for about 30 seconds (the longer you look, the better the effect), and then move your eyes to the blank area to the right of it, you will see the afterimage. When we stare at the green stripes, our green receptors habituate and begin to process less strongly, whereas the red receptors remain at full strength. When we switch our gaze, we see primarily the red part of the opponent process. Similar processes create blue after yellow and white after black.</p>
        <div class="figure large editable block" id="stangor-ch04_s02_s02_f03">
            <p class="title"><span class="title-prefix">Figure 4.16</span> U.S. Flag</p>
            <img src="section_08/67a9a926daa610a2f90ab5d508770678.jpg">
            <p class="para">The presence of an afterimage is best explained by the opponent-process theory of color perception. Stare at the flag for a few seconds, and then move your gaze to the blank space next to it. Do you see the afterimage?</p>
            <div class="copyright">
                <p class="para">Source: Photo courtesy of Mike Swanson, <a class="link" target="_blank" href="http://en.wikipedia.org/wiki/File:US_flag(inverted).svg">http://en.wikipedia.org/wiki/File:US_flag(inverted).svg</a>.</p>
            </div>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s02_p06">The tricolor and the opponent-process mechanisms work together to produce color vision. When light rays enter the eye, the red, blue, and green cones on the retina respond in different degrees, and send different strength signals of red, blue, and green through the optic nerve. The color signals are then processed both by the ganglion cells and by the neurons in the visual cortex (Gegenfurtner &amp; Kiper, 2003).<span class="footnote" id="fwk-stangor-fn04_018">Gegenfurtner, K. R., &amp; Kiper, D. C. (2003). Color vision. <em class="emphasis">Annual Review of Neuroscience, 26</em>, 181–206.</span></p>
    </div>
    <div class="section" id="stangor-ch04_s02_s03">
        <h2 class="title editable block">Perceiving Form</h2>
        <p class="para editable block" id="stangor-ch04_s02_s03_p01">One of the important processes required in vision is the perception of form. German psychologists in the 1930s and 1940s, including Max Wertheimer (1880–1943), Kurt Koffka (1886–1941), and Wolfgang Köhler (1887–1967), argued that we create forms out of their component sensations based on the idea of the <span class="margin_term"><a class="glossterm">gestalt</a><span class="glossdef">A meaningful organized whole.</span></span>, <em class="emphasis">a meaningfully organized whole</em>. The idea of the gestalt is that the “whole is more than the sum of its parts.” Some examples of how gestalt principles lead us to see more than what is actually there are summarized in <a class="xref" href="#stangor-ch04_s02_s03_t01">Table 4.1 "Summary of Gestalt Principles of Form Perception"</a>.</p>
        <div class="table block" id="stangor-ch04_s02_s03_t01" frame="all">
            <p class="title"><span class="title-prefix">Table 4.1</span> Summary of Gestalt Principles of Form Perception</p>
            <table cellpadding="0" cellspacing="0">
                <thead>
                    <tr>
                        <th valign="top">Principle</th>
                        <th valign="top">Description</th>
                        <th valign="top">Example</th>
                        <th>Image</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td valign="top">Figure and ground</td>
                        <td valign="top">We structure input such that we always see a figure (image) against a ground (background).</td>
                        <td valign="top">At right, you may see a vase or you may see two faces, but in either case, you will organize the image as a figure against a ground.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.1</span> </p>
                    <img src="section_08/d100af2425fc65bd44d660e20df82bee.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Similarity</td>
                        <td valign="top">Stimuli that are similar to each other tend to be grouped together.</td>
                        <td valign="top">You are more likely to see three similar columns among the <em class="emphasis">XYX</em> characters at right than you are to see four rows.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.1</span> </p>
                    <img src="section_08/99698f39231a8216ea794b0cbb3749d4.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Proximity</td>
                        <td valign="top">We tend to group nearby figures together.</td>
                        <td valign="top">Do you see four or eight images at right? Principles of proximity suggest that you might see only four.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.1</span> </p>
                    <img src="section_08/b363b29d182282b10681e34e9cf5ffe7.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Continuity</td>
                        <td valign="top">We tend to perceive stimuli in smooth, continuous ways rather than in more discontinuous ways.</td>
                        <td valign="top">At right, most people see a line of dots that moves from the lower left to the upper right, rather than a line that moves from the left and then suddenly turns down. The principle of continuity leads us to see most lines as following the smoothest possible path.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.1</span> </p>
                    <img src="section_08/be9842547ed5489f1b124614ee57d0b6.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Closure</td>
                        <td valign="top">We tend to fill in gaps in an incomplete image to create a complete, whole object.</td>
                        <td valign="top">Closure leads us to see a single spherical object at right rather than a set of unrelated cones.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.1</span> </p>
                    <img src="section_08/fe704ab1f4b03f5281118eb5fba6ca91.jpg">
                </div>
</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>
    <div class="section" id="stangor-ch04_s02_s04">
        <h2 class="title editable block">Perceiving Depth</h2>
        <p class="para editable block" id="stangor-ch04_s02_s04_p01"><span class="margin_term"><a class="glossterm">Depth perception</a><span class="glossdef">The ability to perceive three-dimensional space and to accurately judge distance.</span></span> is <em class="emphasis">the ability to perceive three-dimensional space and to accurately judge distance</em>. Without depth perception, we would be unable to drive a car, thread a needle, or simply navigate our way around the supermarket (Howard &amp; Rogers, 2001).<span class="footnote" id="fwk-stangor-fn04_019">Howard, I. P., &amp; Rogers, B. J. (2001). <em class="emphasis">Seeing in depth: Basic mechanisms</em> (Vol. 1). Toronto, Ontario, Canada: Porteous.</span> Research has found that depth perception is in part based on innate capacities and in part learned through experience (Witherington, 2005).<span class="footnote" id="fwk-stangor-fn04_020">Witherington, D. C. (2005). The development of prospective grasping control between 5 and 7 months: A longitudinal study. <em class="emphasis">Infancy, 7</em>(2), 143–161.</span></p>
        <p class="para editable block" id="stangor-ch04_s02_s04_p02">Psychologists Eleanor Gibson and Richard Walk (1960)<span class="footnote" id="fwk-stangor-fn04_021">Gibson, E. J., &amp; Walk, R. D. (1960). The “visual cliff.” <em class="emphasis">Scientific American, 202</em>(4), 64–71.</span> tested the ability to perceive depth in 6- to 14-month-old infants by placing them on a <span class="margin_term"><a class="glossterm">visual cliff</a><span class="glossdef">A mechanism that gives the perception of a dangerous drop-off, in which infants can be safely tested for their perception of depth.</span></span>, <em class="emphasis">a mechanism that gives the perception of a dangerous drop-off, in which infants can be safely tested for their perception of depth</em> (<a class="xref" href="#stangor-ch04_s02_s04_f01">Figure 4.22 "Visual Cliff"</a>). The infants were placed on one side of the “cliff,” while their mothers called to them from the other side. Gibson and Walk found that most infants either crawled away from the cliff or remained on the board and cried because they wanted to go to their mothers, but the infants perceived a chasm that they instinctively could not cross. Further research has found that even very young children who cannot yet crawl are fearful of heights (Campos, Langer, &amp; Krowitz, 1970).<span class="footnote" id="fwk-stangor-fn04_022">Campos, J. J., Langer, A., &amp; Krowitz, A. (1970). Cardiac responses on the visual cliff in prelocomotor human infants. <em class="emphasis">Science, 170</em>(3954), 196–197.</span> On the other hand, studies have also found that infants improve their hand-eye coordination as they learn to better grasp objects and as they gain more experience in crawling, indicating that depth perception is also learned (Adolph, 2000).<span class="footnote" id="fwk-stangor-fn04_023">Adolph, K. E. (2000). Specificity of learning: Why infants fall over a veritable cliff. <em class="emphasis">Psychological Science, 11</em>(4), 290–295.</span></p>
        <div class="figure medium editable block" id="stangor-ch04_s02_s04_f01">
            <p class="title"><span class="title-prefix">Figure 4.22</span> Visual Cliff</p>
            <img src="section_08/d1e75b295fea106a4993041561b2431d.jpg">
            <p class="para">Babies appear to have the innate ability to perceive depth, as seen by this baby’s reluctance to cross the “visual cliff.”</p>
        </div>
        <p class="para editable block" id="stangor-ch04_s02_s04_p03">Depth perception is the result of our use of <span class="margin_term"><a class="glossterm">depth cues</a><span class="glossdef">Messages from our bodies and the external environment that supply us with information about space and distance.</span></span>, <em class="emphasis">messages from our bodies and the external environment that supply us with information about space and distance</em>. <span class="margin_term"><a class="glossterm">Binocular depth cues</a><span class="glossdef">Depth cues that are created by retinal disparity—that is, the space between our eyes, and thus require the coordination of both eyes.</span></span> are <em class="emphasis">depth cues that are created by retinal image disparity—that is, the space between our eyes, and thus which require the coordination of both eyes.</em> One outcome of retinal disparity is that the images projected on each eye are slightly different from each other. The visual cortex automatically merges the two images into one, enabling us to perceive depth. Three-dimensional movies make use of retinal disparity by using 3-D glasses that the viewer wears to create a different image on each eye. The perceptual system quickly, easily, and unconsciously turns the disparity into 3-D.</p>
        <p class="para editable block" id="stangor-ch04_s02_s04_p04">An important binocular depth cue is <span class="margin_term"><a class="glossterm">convergence</a><span class="glossdef">The inward turning of our eyes that is required to focus on objects that are less than about 50 feet away from us.</span></span>, <em class="emphasis">the inward turning of our eyes that is required to focus on objects that are less than about 50 feet away from us</em>. The visual cortex uses the size of the convergence angle between the eyes to judge the object’s distance. You will be able to feel your eyes converging if you slowly bring a finger closer to your nose while continuing to focus on it. When you close one eye, you no longer feel the tension—convergence is a binocular depth cue that requires both eyes to work.</p>
        <p class="para editable block" id="stangor-ch04_s02_s04_p05">The visual system also uses <em class="emphasis">accommodation</em> to help determine depth. As the lens changes its curvature to focus on distant or close objects, information relayed from the muscles attached to the lens helps us determine an object’s distance. Accommodation is only effective at short viewing distances, however, so while it comes in handy when threading a needle or tying shoelaces, it is far less effective when driving or playing sports.</p>
        <p class="para editable block" id="stangor-ch04_s02_s04_p06">Although the best cues to depth occur when both eyes work together, we are able to see depth even with one eye closed. <span class="margin_term"><a class="glossterm">Monocular depth cues</a><span class="glossdef">Depth cues that help us perceive depth using only one eye.</span></span> are <em class="emphasis">depth cues that help us perceive depth using only one eye</em> (Sekuler &amp; Blake, 2006).<span class="footnote" id="fwk-stangor-fn04_024">Sekuler, R., &amp; Blake, R., (2006). <em class="emphasis">Perception</em> (5th ed.). New York, NY: McGraw-Hill.</span> Some of the most important are summarized in <a class="xref" href="#stangor-ch04_s02_s04_t01">Table 4.2 "Monocular Depth Cues That Help Us Judge Depth at a Distance"</a>.</p>
        <div class="table block" id="stangor-ch04_s02_s04_t01" frame="all">
            <p class="title"><span class="title-prefix">Table 4.2</span> Monocular Depth Cues That Help Us Judge Depth at a Distance</p>
            <table cellpadding="0" cellspacing="0">
                <thead>
                    <tr>
                        <th valign="top">Name</th>
                        <th valign="top">Description</th>
                        <th valign="top">Example</th>
                        <th>Image</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td valign="top">Position</td>
                        <td valign="top">We tend to see objects higher up in our field of vision as farther away.</td>
                        <td valign="top">The fence posts at right appear farther away not only because they become smaller but also because they appear higher up in the picture.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/11c927f0362c81f3b3224b5d63d957f5.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Relative size</td>
                        <td valign="top">Assuming that the objects in a scene are the same size, smaller objects are perceived as farther away.</td>
                        <td valign="top">At right, the cars in the distance appear smaller than those nearer to us.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/e357ef81776891141727c38d4fda04bc.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Linear perspective</td>
                        <td valign="top">Parallel lines appear to converge at a distance.</td>
                        <td valign="top">We know that the tracks at right are parallel. When they appear closer together, we determine they are farther away.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/9523d5f9ea3dd06105cca124d0172f2a.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Light and shadow</td>
                        <td valign="top">The eye receives more reflected light from objects that are closer to us. Normally, light comes from above, so darker images are in shadow.</td>
                        <td valign="top">We see the images at right as extending and indented according to their shadowing. If we invert the picture, the images will reverse.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/316581f492f9b3e09e7a379cdccf2417.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Interposition</td>
                        <td valign="top">When one object overlaps another object, we view it as closer.</td>
                        <td valign="top">At right, because the blue star covers the pink bar, it is seen as closer than the yellow moon.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/5b500b855d7b8eb7a8affdfa917a652b.jpg">
                </div>
</td>
                    </tr>
                    <tr>
                        <td valign="top">Aerial perspective</td>
                        <td valign="top">Objects that appear hazy, or that are covered with smog or dust, appear farther away.</td>
                        <td valign="top">The artist who painted the picture on the right used aerial perspective to make the clouds more hazy and thus appear farther away.</td>
                        <td>                <div class="figure small">
                    <p class="title"><span class="title-prefix">Figure 4.2</span> </p>
                    <img src="section_08/f12c0629442303f66ecca4dddd77ee71.jpg">
                </div>
</td>
                    </tr>
                </tbody>
            </table>
                    <div class="copyright">
                <p class="para">Photo sources: TBD</p>
            </div>
        </div>
    </div>
    <div class="section" id="stangor-ch04_s02_s05">
        <h2 class="title editable block">Perceiving Motion</h2>
        <p class="para editable block" id="stangor-ch04_s02_s05_p01">Many animals, including human beings, have very sophisticated perceptual skills that allow them to coordinate their own motion with the motion of moving objects in order to create a collision with that object. Bats and birds use this mechanism to catch up with prey, dogs use it to catch a Frisbee, and humans use it to catch a moving football. The brain detects motion partly from the changing size of an image on the retina (objects that look bigger are usually closer to us) and in part from the relative brightness of objects.</p>
        <p class="para editable block" id="stangor-ch04_s02_s05_p02">We also experience motion when objects near each other change their appearance. The <span class="margin_term"><a class="glossterm">beta effect</a><span class="glossdef">The perception of motion that occurs when different images are presented next to each other in succession.</span></span> refers to <em class="emphasis">the perception of motion that occurs when different images are presented next to each other in succession</em> (see <a class="xref" href="#stangor-ch04_s02_s05_n01">Note 4.43 "Beta Effect and Phi Phenomenon"</a>). The visual cortex fills in the missing part of the motion and we see the object moving. The beta effect is used in movies to create the experience of motion. A related effect is the <span class="margin_term"><a class="glossterm">phi phenomenon</a><span class="glossdef">The perception of motion caused by the appearance and disappearance of objects that are near each other.</span></span>, in which <em class="emphasis">we perceive a sensation of motion caused by the appearance and disappearance of objects that are near each other</em>. The phi phenomenon looks like a moving zone or cloud of background color surrounding the flashing objects. The beta effect and the phi phenomenon are other examples of the importance of the gestalt—our tendency to “see more than the sum of the parts.”</p>
        <div class="callout editable block" id="stangor-ch04_s02_s05_n01">
            <h3 class="title">Beta Effect and Phi Phenomenon</h3>
            <p class="para" id="stangor-ch04_s02_s05_p03">In the beta effect, our eyes detect motion from a series of still images, each with the object in a different place. This is the fundamental mechanism of motion pictures (movies). In the phi phenomenon, the perception of motion is based on the momentary hiding of an image.</p>
            <p class="para" id="stangor-ch04_s02_s05_p04">Phi phenomenon: <a class="link" target="_blank" href="http://upload.wikimedia.org/wikipedia/commons/6/6e/Lilac-Chaser.gif">http://upload.wikimedia.org/wikipedia/commons/6/6e/Lilac-Chaser.gif</a></p>
            <p class="para" id="stangor-ch04_s02_s05_p05">Beta effect: <a class="link" target="_blank" href="http://upload.wikimedia.org/wikipedia/commons/0/09/Phi_phenomenom_no_watermark.gif">http://upload.wikimedia.org/wikipedia/commons/0/09/Phi_phenomenom_no_watermark.gif</a></p>
        </div>
        <div class="key_takeaways editable block" id="stangor-ch04_s02_s05_n02">
            <h3 class="title">Key Takeaways</h3>
            <ul class="itemizedlist" id="stangor-ch04_s02_s05_l01">
                <li>Vision is the process of detecting the electromagnetic energy that surrounds us. Only a small fraction of the electromagnetic spectrum is visible to humans.</li>
                <li>The visual receptor cells on the retina detect shape, color, motion, and depth.</li>
                <li>Light enters the eye through the transparent cornea and passes through the pupil at the center of the iris. The lens adjusts to focus the light on the retina, where it appears upside down and backward. Receptor cells on the retina are excited or inhibited by the light and send information to the visual cortex through the optic nerve.</li>
                <li>The retina has two types of photoreceptor cells: rods, which detect brightness and respond to black and white, and cones, which respond to red, green, and blue. Color blindness occurs when people lack function in the red- or green-sensitive cones.</li>
                <li>Feature detector neurons in the visual cortex help us recognize objects, and some neurons respond selectively to faces and other body parts.</li>
                <li>The Young-Helmholtz trichromatic color theory proposes that color perception is the result of the signals sent by the three types of cones, whereas the opponent-process color theory proposes that we perceive color as three sets of opponent colors: red-green, yellow-blue, and white-black.</li>
                <li>The ability to perceive depth occurs through the result of binocular and monocular depth cues.</li>
                <li>Motion is perceived as a function of the size and brightness of objects. The beta effect and the phi phenomenon are examples of perceived motion.</li>
            </ul>
        </div>
        <div class="exercises editable block" id="stangor-ch04_s02_s05_n03">
            <h3 class="title">Exercises and Critical Thinking</h3>
            <ol class="orderedlist" id="stangor-ch04_s02_s05_l02">
                <li>Consider some ways that the processes of visual perception help you engage in an everyday activity, such as driving a car or riding a bicycle.</li>
                <li>Imagine for a moment what your life would be like if you couldn’t see. Do you think you would be able to compensate for your loss of sight by using other senses?</li>
            </ol>
        </div>
    </div>
</div>

  </div>
  
  <div id=navbar-bottom class="navbar">
    <div class="navbar-part left">
      
        <a href="s08-01-we-experience-our-world-throug.html"><img src="shared/images/batch-left.png"></a> <a href="s08-01-we-experience-our-world-throug.html">Previous Section</a>
      
    </div>
    <div class="navbar-part middle">
      <a href="index.html"><img src="shared/images/batch-up.png"></a> <a href="index.html">Table of Contents</a>
    </div>
    <div class="navbar-part right">
      
        <a href="s08-03-hearing.html">Next Section</a> <a href="s08-03-hearing.html"><img src="shared/images/batch-right.png"></a>
      
    </div>
  </div>

  </div>
  <script type="text/javascript" src="shared/book.js"></script>
  
  
</body>
</html>
